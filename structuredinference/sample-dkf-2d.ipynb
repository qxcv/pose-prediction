{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sampling 2D pose DKF trained on (any) 2D pose database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The next few variables are important for choosing *which* dataset/model should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DS = 'ikeadb'\n",
    "\n",
    "if DS == 'ikeadb':\n",
    "    DS_DIR = './expt-ikeadb/'\n",
    "    PFX = DS_DIR + 'chkpt-ikeadb/'\n",
    "    # CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-ikeadb-acts-config.pkl'\n",
    "    # WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-ikeadb-acts-EP125-params.npz'\n",
    "    # EXTRA_ARGS = '-vm LR -cond -infm structured -ds 50 -dh 50 -uid ikeadb-acts -cond'.split()\n",
    "    # v XXX: this is the non-action-conditioned version\n",
    "    CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-ikeadb-no-acts-config.pkl'\n",
    "    WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-ikeadb-no-acts-EP200-params.npz'\n",
    "    EXTRA_ARGS = '-vm LR -infm structured -ds 50 -dh 50 -uid ikeadb-no-acts'.split()\n",
    "    # ^ XXX\n",
    "    ACTION_PFX = DS_DIR + 'chkpt-aclass/'\n",
    "    ACTION_MODEL_PATH = ACTION_PFX + 'action-classifier-92-0.62.hdf5'\n",
    "    ACTION_MODEL_META_PATH = ACTION_PFX + 'meta.json'\n",
    "elif DS == 'penn':\n",
    "    DS_DIR = './expt-penn-action/'\n",
    "    PFX = DS_DIR + 'chkpt-penn/'\n",
    "    CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-L-inf-structured-dh-50-ds-10-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-penn-acts-config.pkl'\n",
    "    WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-L-inf-structured-dh-50-ds-10-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-penn-acts-EP1975-params.npz'\n",
    "    EXTRA_ARGS = '-vm L -infm structured -ds 10 -dh 50 -uid penn-acts'.split()\n",
    "elif DS == 'mpii-ca2':\n",
    "    DS_DIR = './expt-mpii-ca2/'\n",
    "    PFX = DS_DIR + 'chkpt-mpii-ca2/'\n",
    "    # CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-100-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-mpii-ca2-bidi-actions-config.pkl'\n",
    "    # WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-100-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-mpii-ca2-bidi-actions-EP225-params.npz'\n",
    "    # EXTRA_ARGS = '-vm LR -infm structured -ds 100 -dh 50 -cond -uid mpii-ca2-bidi-actions'.split()\n",
    "    # v XXX: this is the non-action-conditioned version\n",
    "    # CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-10-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-mpii-ca2-no-acts-config.pkl'\n",
    "    # WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-10-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-mpii-ca2-no-acts-EP250-params.npz'\n",
    "    # EXTRA_ARGS = '-vm LR -infm structured -ds 10 -dh 50 -uid mpii-ca2-no-acts'.split()\n",
    "    # ^ XXX\n",
    "    ACTION_MODEL_PATH = 'expt-mpii-ca2/chkpt-aclass/action-classifier-42-1.99.hdf5'\n",
    "    ACTION_MODEL_META_PATH = 'expt-mpii-ca2/chkpt-aclass/meta.json'\n",
    "elif DS == 'h36m-2d':\n",
    "    DS_DIR = './expt-h36m-2d/'\n",
    "    PFX = DS_DIR + 'chkpt-h36m-2d/'\n",
    "    ACTION_MODEL_PATH = DS_DIR + 'chkpt-aclass/' + 'action-classifier-89-0.56.hdf5'\n",
    "    ACTION_MODEL_META_PATH = DS_DIR + 'chkpt-aclass/meta.json'\n",
    "    \n",
    "    # action\n",
    "    # CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-h36m-2d-acts-config.pkl'\n",
    "    # WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-h36m-2d-acts-EP75-params.npz'\n",
    "    # EXTRA_ARGS = '-vm LR -infm structured -ds 50 -cond -dh 50 -uid h36m-2d-acts'.split()\n",
    "    \n",
    "    # no actions\n",
    "    # CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-h36m-2d-no-acts-config.pkl'\n",
    "    # WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-h36m-2d-no-acts-EP125-params.npz'\n",
    "    # EXTRA_ARGS = '-vm LR -infm structured -ds 50 -dh 50 -uid h36m-2d-no-acts'.split()\n",
    "    \n",
    "    # conditional emission distribution, no actions\n",
    "    CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-conditional-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-h36m-2d-econd-no-acts-config.pkl'\n",
    "    WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-LR-inf-structured-dh-50-ds-50-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-conditional-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-False-h36m-2d-econd-no-acts-EP75-params.npz'\n",
    "    EXTRA_ARGS = '-vm LR -infm structured -ds 50 -dh 50 -etype conditional -uid h36m-2d-econd-no-acts'.split()\n",
    "else:\n",
    "    raise ValueError('Unknown dataset %s' % DS)\n",
    "\n",
    "import sys\n",
    "sys.path.append(DS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hacky way of preventing the notebook from doing some irrelevant stuff, sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DO_GENERATE_SAMPLES = True\n",
    "DO_CLASSIFIER_SVM = False\n",
    "DO_GENERATE_COMPLETIONS = True\n",
    "DO_FORECAST_EVAL = False\n",
    "DO_EASY_FORECAST_EVAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import load_model\n",
    "import theano\n",
    "import tqdm\n",
    "\n",
    "import addpaths\n",
    "from load import loadDataset\n",
    "import p2d_loader\n",
    "from common_pp.act_pre_common import balance_aclass_ds, merge_actions, \\\n",
    "    one_hot_cat, one_hot_max, classifier_transform\n",
    "# ugh, why did I call this common? It's in ~/repos/pose-prediction/keras/\n",
    "from common import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del sys.argv[1:]\n",
    "\n",
    "sys.argv.extend(EXTRA_ARGS)\n",
    "sys.argv.extend(['-reload', WEIGHT_PATH, '-params', CONFIG_PATH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_dir = os.getcwd()\n",
    "try:\n",
    "    os.chdir(DS_DIR)\n",
    "    dataset = loadDataset()\n",
    "finally:\n",
    "    os.chdir(old_dir)\n",
    "db = dataset['p2d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_poses = dataset['train']\n",
    "train_poses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from parse_args_dkf import parse; params = parse()\n",
    "from utils.misc import removeIfExists,createIfAbsent,mapPrint,saveHDF5,displayTime\n",
    "from stinfmodel_fast.dkf import DKF\n",
    "import stinfmodel_fast.learning as DKF_learn\n",
    "import stinfmodel_fast.evaluate as DKF_evaluate\n",
    "from theano import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if db.have_actions:\n",
    "    act_names = db.action_names\n",
    "    for idx, name in enumerate(act_names):\n",
    "        print('ID% 3i (action% 3i/%i): %s' % (idx, idx+1, len(act_names), name))\n",
    "    one_hot_acts = {}\n",
    "    hot_vec_size = len(act_names)\n",
    "    for hot_bit, name in enumerate(act_names):\n",
    "        one_hot_acts[name] = (np.arange(hot_vec_size) == hot_bit)\n",
    "parents = db.parents\n",
    "print('Parents array: %s' % parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_cond = bool(params.get('use_cond', False))\n",
    "params['savedir']+=PFX\n",
    "\n",
    "# Add dataset and NADE parameters to \"params\" which will become part of the\n",
    "# model\n",
    "for k in ['dim_observations','data_type']:\n",
    "    params[k] = dataset[k]\n",
    "mapPrint('Options: ',params)\n",
    "if params['use_nade']:\n",
    "    params['data_type']='real_nade'\n",
    "\n",
    "# Remove from params\n",
    "removeIfExists('./NOSUCHFILE')\n",
    "reloadFile = params.pop('reloadFile')\n",
    "pfile=params.pop('paramFile')\n",
    "# paramFile is set inside the BaseClass in theanomodels\n",
    "# to point to the pickle file containing params\"\"\"\n",
    "assert os.path.exists(pfile),pfile+' not found. Need paramfile'\n",
    "print 'Reloading trained model from : ',reloadFile\n",
    "print 'Assuming ',pfile,' corresponds to model'\n",
    "dkf  = DKF(params, paramFile = pfile, reloadFile = reloadFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def smooth_seq(seq):\n",
    "    assert seq.ndim in {2, 3}, seq.shape\n",
    "    if seq.ndim == 3:\n",
    "        rv = np.zeros_like(seq)\n",
    "        for r in range(len(seq)):\n",
    "            rv[r] = p2d_loader.gauss_filter(seq[r], sigma=1.0)\n",
    "        return rv\n",
    "    # 2d, filter whole thing\n",
    "    return p2d_loader.gauss_filter(seq, sigma=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Non-action-conditional modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_any(poses, count):\n",
    "    indices = np.random.permutation(len(poses))[:count]\n",
    "    out_data = poses[indices]\n",
    "    return db.reconstruct_poses(out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not use_cond and DO_GENERATE_SAMPLES:\n",
    "    # No need to do conditional nonsense!\n",
    "    num_seqs = 32\n",
    "    seq_length = 256\n",
    "    dest_dir = DS_DIR + 'generated/'\n",
    "    try:\n",
    "        os.makedirs(dest_dir)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    oodles_of_samples = dkf.sample(nsamples=num_seqs, T=seq_length)\n",
    "    sample_X, sample_Z = oodles_of_samples\n",
    "    real_X = db.reconstruct_poses(sample_X)\n",
    "        \n",
    "    # Scrape some training poses, too\n",
    "    train_poses = scrape_any(\n",
    "        dataset['train'],\n",
    "        num_seqs)\n",
    "    val_poses = scrape_any(\n",
    "        dataset['val'],\n",
    "        num_seqs)\n",
    "        \n",
    "    smooth_sampled_times = smooth_seq(\n",
    "        real_X.reshape(real_X.shape[:2] + (-1,))\n",
    "    ).reshape(real_X.shape[:2] + (2, -1))\n",
    "    dest_fn = os.path.join(dest_dir, 'generated.npz')\n",
    "    print('Saving ' + dest_fn)\n",
    "    np.savez(\n",
    "        dest_fn, poses_gen=real_X,\n",
    "        poses_smooth=smooth_sampled_times,\n",
    "        poses_train=train_poses,\n",
    "        poses_val=val_poses,\n",
    "        parents=parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Action-conditional modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_by_act(poses, actions, one_hot_rep, count):\n",
    "    # actions should be N*T*A\n",
    "    # from IPython.core.debugger import Tracer; Tracer()()\n",
    "    assert np.prod(one_hot_rep.shape) == one_hot_rep.size, \\\n",
    "        \"one-hot rep must be a vector\"\n",
    "    act_num = np.argmax(one_hot_rep.flatten())\n",
    "    assert actions.ndim == 3, actions.shape\n",
    "    act_nums = np.argmax(actions, axis=2)\n",
    "    assert act_nums.shape == poses.shape[:2], \\\n",
    "        \"mismatched action shape %s and pose shape %s\" \\\n",
    "            % (actions.shape, poses.shape)\n",
    "    # try to find sequences that feature part of the action\n",
    "    has_act, = np.nonzero((act_num == act_nums).any(axis=1))\n",
    "    indices = has_act[np.random.permutation(len(has_act))][:count]\n",
    "    if len(indices) < count:\n",
    "        print('Only found %d instances of action with ID %d'\n",
    "              % (len(indices), act_num))\n",
    "    if not len(indices):\n",
    "        return\n",
    "    out_data = poses[indices]\n",
    "    return db.reconstruct_poses(out_data)\n",
    "\n",
    "def sanitise_name(name):\n",
    "    # for sanitising filenames\n",
    "    return re.sub(r'[^a-z0-9_-]+', '-', name.lower()).strip('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_cond and DO_GENERATE_SAMPLES:\n",
    "    seqs_per_act = 9\n",
    "    seq_length = 128\n",
    "    dest_dir = DS_DIR + 'generated-wacts/'\n",
    "    try:\n",
    "        os.makedirs(dest_dir)\n",
    "    except OSError:\n",
    "        pass\n",
    "        \n",
    "    # start by generating some sequences for each action type\n",
    "    for act_name, one_hot_rep in one_hot_acts.items():\n",
    "        print('Working on action %s' % act_name)\n",
    "        U = np.stack([one_hot_rep] * seq_length, axis=0)\n",
    "        oodles_of_samples = dkf.sample(nsamples=seqs_per_act, T=seq_length, U=U)\n",
    "        sample_X, sample_Z = oodles_of_samples\n",
    "        real_X = db.reconstruct_poses(sample_X)\n",
    "        \n",
    "        # Scrape some training poses, too\n",
    "        train_poses = scrape_by_act(\n",
    "            dataset['train'],\n",
    "            dataset['train_cond_vals'],\n",
    "            one_hot_rep,\n",
    "            seqs_per_act)\n",
    "        val_poses = scrape_by_act(\n",
    "            dataset['val'],\n",
    "            dataset['val_cond_vals'],\n",
    "            one_hot_rep,\n",
    "            seqs_per_act)\n",
    "        \n",
    "        njoints = len(parents)\n",
    "        smooth_sampled_times = smooth_seq(\n",
    "            real_X.reshape(real_X.shape[:2] + (njoints*2,))\n",
    "        ).reshape(real_X.shape[:2] + (2, njoints))\n",
    "        actn = sanitise_name(act_name)\n",
    "        dest_pfx = os.path.join(dest_dir, 'act-%s' % actn)\n",
    "        dest_fn = dest_pfx + '.npz'\n",
    "        print('Saving ' + dest_fn)\n",
    "        np.savez(\n",
    "            dest_fn, poses_gen=real_X,\n",
    "            poses_smooth=smooth_sampled_times,\n",
    "            poses_train=train_poses,\n",
    "            poses_val=val_poses,\n",
    "            parents=parents\n",
    "        )\n",
    "\n",
    "    # now choose random pairs of (distinct) actions and simulate\n",
    "    # a transition at half-way point\n",
    "    num_pairs = 10\n",
    "    nacts = len(act_names)\n",
    "    chosen_idxs = np.random.permutation(nacts * (nacts-1))[:num_pairs]\n",
    "    act_pairs = [(act_names[idxp%nacts], act_names[idxp//nacts]) \\\n",
    "                 for idxp in chosen_idxs]\n",
    "    for act1, act2 in act_pairs:\n",
    "        print('Computing sequence for action %s -> %s' % (act1, act2))\n",
    "        \n",
    "        len1 = seq_length // 2\n",
    "        len2 = seq_length - len1\n",
    "        rep1 = one_hot_acts[act1]\n",
    "        rep2 = one_hot_acts[act2]\n",
    "        U = np.stack([rep1] * len1 + [rep2] * len2, axis=0)\n",
    "        oodles_of_samples = dkf.sample(nsamples=seqs_per_act, T=seq_length, U=U)\n",
    "        sample_X, sample_Z = oodles_of_samples\n",
    "        real_X = db.reconstruct_poses(sample_X)\n",
    "        \n",
    "        smooth_sampled_times = smooth_seq(\n",
    "            real_X.reshape(real_X.shape[:2] + (len(parents) * 2,))\n",
    "        ).reshape(real_X.shape[:2] + (2, len(parents)))\n",
    "        act1n = sanitise_name(act1)\n",
    "        act2n = sanitise_name(act2)\n",
    "        dest_pfx = os.path.join(\n",
    "            dest_dir,\n",
    "            'trans-%s-to-%s' % (act1n, act2n))\n",
    "        dest_fn = dest_pfx + '.npz'\n",
    "        print('Saving ' + dest_fn)\n",
    "        np.savez(\n",
    "            dest_fn,\n",
    "            poses_trans=real_X,\n",
    "            poses_trans_smooth=smooth_sampled_times,\n",
    "            parents=parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Action classification\n",
    "\n",
    "The next section of the notebook will be dedicated to action classification using the pose DKF. Rougly, the setup is this:\n",
    "    \n",
    "1. Extract a sequences of poses $k$ poses, $p_{t:t+k-1}$, associated with a given action. I will try to make sure that $k \\geq 10$ (or that $k$ is otherwise suitably long).\n",
    "2. Run the inference network over $p_{t:t+k-1}$ to obtain $z_{t:t+k-1}$.\n",
    "3. Pass a pooled representation of the latent vectors into an SVM for classification (e.g. mean of values).\n",
    "\n",
    "Some fine points:\n",
    "\n",
    "- The current model is trained to require actions as input at each step of the encoder *and* decoder. Given that actions must be supplied to the network at each time step, it's not clear what an action classifier on top of the latents actually achieves. Here are some possible ways of dealing with that:\n",
    "   1. Ignore it. See if the SVM can recover the given action labels from latents alone. Doing so isn't terribly impressive, but *failing* to do so would be strong evidence that this is a poor approach to action classification (**what I'm doing right now**; I'll do something more intelligent for Penn and MPII).\n",
    "   2. Give the network random actions so as not to bias it. Unfortunately, the network isn't actually trained on random actions, so this could make the results meaningless.\n",
    "   3. Train a new model where the decoder is not action-conditional. The encoder could be action-conditional or non-action-conditional; again, it's unclear whether this will improve or harm classification accuracy when using latents.\n",
    "- The whole pipeline is likely to be sensitive to the latent pooling method used. Will have to experiment with picking the last latent, as well as mean/sum/max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def seq_latents(feat_sequence, true_action=None):\n",
    "    # must be (T, D)\n",
    "    assert feat_sequence.ndim == 2, feat_sequence.shape\n",
    "    cond_vals = None\n",
    "    if use_cond:\n",
    "        assert true_action is not None, \\\n",
    "            'need true action because latents are action-conditional'\n",
    "        cond_vals = np.zeros((1, len(feat_sequence), len(act_names)), dtype='float32')\n",
    "        cond_vals[0, range(len(feat_sequence)), true_action] = 1\n",
    "    mask = np.ones((1, len(feat_sequence),))\n",
    "    # the zs are just samples\n",
    "    # maybe I should get more of them? just a matter of calling .infer twice\n",
    "    feat_in = feat_sequence[np.newaxis, ...].astype('float32')\n",
    "    z, mu, logcov = DKF_evaluate.infer(dkf, feat_sequence[np.newaxis, ...], mask, cond_vals=cond_vals)\n",
    "    # TODO: what if I condition on cat[mu, logcov] instead? Noise from z computation\n",
    "    # *might* act as a regulariser, but it might also just be noise :P\n",
    "    return z[0]\n",
    "    \n",
    "def to_latent_ds(ds):\n",
    "    \"\"\"Convert a list of (pose sequence, action ID) pairs into a dataset\n",
    "    consisting of a matrix of latents (corresponding to pose sequences)\n",
    "    and a vector of action IDs (as supplied).\"\"\"\n",
    "    X_blocks = []\n",
    "    Y_blocks = []\n",
    "    seen = 0\n",
    "    for feat_seq, true_act in ds:\n",
    "        seen += 1\n",
    "        if seen == 1 or seen % 250 == 0:\n",
    "            print('Working on sequence %d' % seen)\n",
    "        latents = seq_latents(feat_seq, true_act)\n",
    "        # take the mean\n",
    "        # lat_val = latents.mean(axis=0)\n",
    "        # take the last\n",
    "        lat_val = latents[-1]\n",
    "        X_blocks.append(lat_val)\n",
    "        Y_blocks.append(true_act)\n",
    "\n",
    "    X = np.stack(X_blocks)\n",
    "    Y = np.array(Y_blocks)\n",
    "    assert X.ndim == 2, X.shape\n",
    "    assert Y.ndim == 1, Y.shape\n",
    "    assert X.shape[0] ==  Y.shape[0], (X.shape, Y.shape)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The next cell is slooooow. Could probably speed it up with batching, but IMO not worth the effort at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if db.have_actions and DO_CLASSIFIER_SVM:\n",
    "    train_aclass_ds = dataset['train_aclass_ds']\n",
    "    val_aclass_ds = dataset['val_aclass_ds']\n",
    "    aclass_target_names = act_names\n",
    "    if DS == 'ikeadb':\n",
    "        merge_map = {\n",
    "            'attach leg 1': 'attach leg',\n",
    "            'attach leg 2': 'attach leg',\n",
    "            'attach leg 3': 'attach leg',\n",
    "            'attach leg 4': 'attach leg',\n",
    "            'detach leg 1': 'detach leg',\n",
    "            'detach leg 2': 'detach leg',\n",
    "            'detach leg 3': 'detach leg',\n",
    "            'detach leg 4': 'detach leg',\n",
    "            'n/a': None\n",
    "        }\n",
    "        _, train_aclass_ds \\\n",
    "            = merge_actions(train_aclass_ds, merge_map, act_names)\n",
    "        aclass_target_names, val_aclass_ds \\\n",
    "            = merge_actions(val_aclass_ds, merge_map, act_names)\n",
    "\n",
    "    train_aclass_ds_bal = balance_aclass_ds(train_aclass_ds, aclass_target_names)\n",
    "    train_act_X, train_act_Y = to_latent_ds(train_aclass_ds_bal)\n",
    "    val_aclass_ds_bal = balance_aclass_ds(val_aclass_ds, aclass_target_names)\n",
    "    val_act_X, val_act_Y = to_latent_ds(val_aclass_ds_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if db.have_actions and DO_CLASSIFIER_SVM:\n",
    "    print('Shapes:')\n",
    "    print('train_act_X: {}'.format(train_act_X.shape))\n",
    "    print('train_act_Y: {}'.format(train_act_Y.shape))\n",
    "    print('val_act_X: {}'.format(val_act_X.shape))\n",
    "    print('val_act_Y: {}'.format(val_act_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if db.have_actions and DO_CLASSIFIER_SVM:\n",
    "    model = LinearSVC(C=1)\n",
    "    print('Fitting to training set')\n",
    "    model.fit(train_act_X, train_act_Y)\n",
    "    print('Evaluating SVC on training set')\n",
    "    train_out_Y = model.predict(train_act_X)\n",
    "    print(classification_report(train_act_Y, train_out_Y,\n",
    "                                target_names=aclass_target_names))\n",
    "\n",
    "    print('Evaluating SVC on validation set')\n",
    "    val_out_Y = model.predict(val_act_X)\n",
    "    print(classification_report(val_act_Y, val_out_Y,\n",
    "                                target_names=aclass_target_names))\n",
    "    del train_act_X, train_act_Y, val_act_X, val_act_Y, train_out_Y, val_out_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Inspecting predictions\n",
    "\n",
    "How well is the model actually learning to predict pose sequences? The next section will try to find out by taking short pose sequences from the training set (any action), encoding them, then coming up with several predictions for their continuations (both smoothed and unsmoothed). Eventually, I will superimpose the predictions on the original frames corresponding to the poses for comparison with the ground truth. Obviously, this will require that I output the ground truth as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def smart_emission(dkf, zs, past_X=None):\n",
    "    N, T, Dz = zs.shape\n",
    "    if dkf.params['emission_type'] != 'conditional':\n",
    "        # nothing to do; emission function does not depend\n",
    "        # on other steps\n",
    "        return dkf.emission_fxn(zs)\n",
    "    \n",
    "    # *now* we have the hard case: we need to pass X back\n",
    "    # in to the emission function at each step\n",
    "    Dx = dkf.params['dim_observations']\n",
    "    \n",
    "    if past_X is not None:\n",
    "        # we only need one time step\n",
    "        assert past_X.shape == (N, Dx), \\\n",
    "        \"expected past_X to be %s, got %s tensor\" \\\n",
    "        % ((N, Dx), past_X.shape)\n",
    "        X_in = past_X[:, np.newaxis, :]\n",
    "    else:\n",
    "        X_in = np.zeros((N, 1, Dx), dtype=config.floatX)\n",
    "        \n",
    "    X_out = np.zeros((N, T, Dx), dtype=config.floatX)\n",
    "    \n",
    "    for t in range(T):\n",
    "        z = zs[:, t:t+1]\n",
    "        X_in = X_out[:, t:t+1, :] = dkf.emission_fxn(z, X_in)\n",
    "        assert not np.any(np.isnan(X_in))\n",
    "        \n",
    "    return X_out\n",
    "\n",
    "def make_completion(poses, actions=None, use_post=True, zero_actions=False):\n",
    "    # TODO: should make this batch things\n",
    "    T = len(poses)\n",
    "    T_pre = T // 2\n",
    "    T_post = T - T_pre\n",
    "    \n",
    "    prior_completion = np.zeros_like(poses)\n",
    "    if use_post:\n",
    "        posterior_completion = np.zeros_like(poses)\n",
    "    \n",
    "    if use_cond:\n",
    "        pre_latents = seq_latents(poses[:T_pre], actions[:T_pre])\n",
    "    else:\n",
    "        pre_latents = seq_latents(poses[:T_pre])\n",
    "    prior_completion[:T_pre] \\\n",
    "        = smart_emission(dkf, pre_latents[None, ...])\n",
    "    if use_post:\n",
    "        posterior_completion[:T_pre] = prior_completion[:T_pre]\n",
    "        \n",
    "    z = pre_latents[-1]\n",
    "    assert z.ndim == 1\n",
    "    # z needs to be 3D (nsamples, time, stochdim)\n",
    "    z_prior = z_posterior = z.reshape((1, 1, -1))\n",
    "    if use_post:\n",
    "        z_posterior = z_prior\n",
    "    \n",
    "    if use_cond:\n",
    "        if zero_actions:\n",
    "            oha = one_hot_cat(np.zeros_like(actions), len(act_names))\n",
    "        else:\n",
    "            oha = one_hot_cat(actions, len(act_names))\n",
    "    \n",
    "    for t in range(T_pre, T):\n",
    "        # completion based on prior only\n",
    "        if use_cond:\n",
    "            mu_prior, logcov_prior = dkf.transition_fxn(z_prior, oha[None, t:t+1])\n",
    "        else:\n",
    "            mu_prior, logcov_prior = dkf.transition_fxn(z_prior)\n",
    "        z_prior = DKF_evaluate.sampleGaussian(mu_prior, logcov_prior).astype(config.floatX)\n",
    "        e_prior = smart_emission(dkf, z_prior, prior_completion[None, t-1])\n",
    "        assert e_prior.ndim == 3 and e_prior.shape[:2] == (1, 1)\n",
    "        prior_completion[t] = e_prior[0][0]\n",
    "        \n",
    "        if use_post:\n",
    "            # posterior completion (TODO: use stateful model to make this faster)\n",
    "            if use_cond:\n",
    "                mu_posterior, logcov_posterior = dkf.transition_fxn(z_posterior, oha[None, t:t+1])\n",
    "            else:\n",
    "                mu_posterior, logcov_posterior = dkf.transition_fxn(z_posterior)\n",
    "            # sample z_t from prior distribution to gt x_t\n",
    "            z_posterior = DKF_evaluate.sampleGaussian(mu_posterior, logcov_posterior).astype(config.floatX)\n",
    "            e_posterior = smart_emission(dkf, z_posterior, posterior_completion[None, t-1])\n",
    "            assert e_prior.ndim == 3 and e_posterior.shape[:2] == (1, 1)\n",
    "            posterior_completion[t] = e_posterior[0][0]\n",
    "            # here's the trick: we replace our prior z_t with a posterior\n",
    "            # z_t now that we have x\n",
    "            if use_cond:\n",
    "                z_posterior = seq_latents(posterior_completion[:t], actions[:t])[None, t-1:]\n",
    "            else:\n",
    "                z_posterior = seq_latents(posterior_completion[:t])[None, t-1:]\n",
    "            assert z_posterior.ndim == 3\n",
    "            assert z_posterior.shape[:2] == (1, 1)\n",
    "\n",
    "    if use_post:\n",
    "        return prior_completion, posterior_completion, T_pre\n",
    "    return prior_completion, T_pre\n",
    "\n",
    "def process_completions(completions, to_select=32, zero_actions=False):\n",
    "    right_indices = np.random.permutation(len(completions))[:to_select]\n",
    "    \n",
    "    rv = []\n",
    "    \n",
    "    for block in np.take(completions, right_indices):\n",
    "        poses = block['poses']\n",
    "        mask = block['mask']\n",
    "        if use_cond:\n",
    "            actions = np.argmax(block['actions'], axis=-1)\n",
    "        else:\n",
    "            actions = None\n",
    "        completion_p, completion_q, crossover = make_completion(poses, actions, zero_actions=zero_actions)\n",
    "        start, stop, skip = block['start'], block['stop'], block['skip']\n",
    "        # need to undo mean subtraction and parent-relative stuff\n",
    "        # to reconstruct poses\n",
    "        recon = lambda data: db.reconstruct_poses(data[None, ...], block['vid_name']).tolist()\n",
    "        \n",
    "        completed_block = {\n",
    "            'vid_name': block['vid_name'],\n",
    "            # I think these indices will be zero-based\n",
    "            # (but datasets are not)\n",
    "            'frame_inds': list(range(start, stop, skip)),\n",
    "            'true_poses': recon(poses)[0],\n",
    "            'prior_poses': recon(completion_p)[0],\n",
    "            'posterior_poses': recon(completion_q)[0],\n",
    "            # time at which we go from using emission function \n",
    "            # on posterior latents to chaining prior evaluation\n",
    "            # + using posterior on that\n",
    "            'crossover_time': crossover,\n",
    "            'mask': (mask != 0).tolist(),\n",
    "            'parents': list(parents)\n",
    "        }\n",
    "        \n",
    "        rv.append(completed_block)\n",
    "    \n",
    "    return rv\n",
    "\n",
    "def save_completions(completions, save_subdir):\n",
    "    save_dir = os.path.join(DS_DIR, save_subdir)\n",
    "    try:\n",
    "        os.makedirs(save_dir)\n",
    "    except OSError:\n",
    "        pass\n",
    "    for block_id, block in enumerate(completions):\n",
    "        file_path = os.path.join(save_dir, '%04d.json' % block_id)\n",
    "        with open(file_path, 'w') as fp:\n",
    "            json.dump(block, fp, indent=2)\n",
    "            \n",
    "def print_completion_stats(comp):\n",
    "    prior_l2s = []\n",
    "    posterior_l2s = []\n",
    "    ext_l2s = []\n",
    "\n",
    "    for block in comp:\n",
    "        cross = block['crossover_time']\n",
    "        # Going to be T*2*J (128*2*7 for IkeaDB)\n",
    "        true_vals = np.asarray(block['true_poses'][cross:])\n",
    "        prior_guesses = np.asarray(block['prior_poses'][cross:])\n",
    "        posterior_guesses = np.asarray(block['posterior_poses'][cross:])\n",
    "        # will broadcast this\n",
    "        ext_guesses = np.asarray(block['true_poses'][cross-1:cross])\n",
    "        \n",
    "        l2_dists = lambda p: np.mean(np.linalg.norm(true_vals - p, axis=1), axis=1)\n",
    "        \n",
    "        prior_l2s.append(l2_dists(prior_guesses))\n",
    "        posterior_l2s.append(l2_dists(posterior_guesses))\n",
    "        ext_l2s.append(l2_dists(ext_guesses))\n",
    "\n",
    "        assert len(prior_l2s[-1]) == len(prior_guesses)\n",
    "        assert len(ext_l2s[-1]) == len(prior_guesses)\n",
    "        assert len(posterior_l2s[-1]) == len(prior_guesses)\n",
    "        \n",
    "    prior_l2 = np.mean(prior_l2s, axis=0)\n",
    "    posterior_l2 = np.mean(posterior_l2s, axis=0)\n",
    "    ext_l2 = np.mean(ext_l2s, axis=0)\n",
    "    \n",
    "    z = zip(prior_l2, posterior_l2, ext_l2)\n",
    "    T = len(prior_l2)\n",
    "    print('       ' + ''.join('% 20s' % n for n in ['p method', 'q method', 'extend']))\n",
    "    for i in range(0, T, T // 5):\n",
    "        cols = ''.join('% 20.2f' % d for d in z[i])\n",
    "        print(('t+% 3d: ' % (i+1)) + cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if 'train_completions' in dataset and DO_GENERATE_COMPLETIONS:\n",
    "    print('Working on train completions')\n",
    "    zero_actions = False\n",
    "    train_comp = process_completions(dataset['train_completions'], to_select=8, zero_actions=zero_actions)\n",
    "    save_completions(train_comp, 'completions/train')\n",
    "    print_completion_stats(train_comp)\n",
    "    del train_comp\n",
    "    \n",
    "    print('Working on val completions')\n",
    "    val_comp = process_completions(dataset['val_completions'], to_select=8, zero_actions=zero_actions)\n",
    "    save_completions(val_comp, 'completions/val')\n",
    "    print_completion_stats(val_comp)\n",
    "    del val_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Full pipeline\n",
    "\n",
    "What needs to be done here:\n",
    "\n",
    "1. Load a trained action predictor\n",
    "2. For each item in the action classification dataset:\n",
    "\n",
    "   1. Use transition dictionary to find action which would follow current one\n",
    "   2. Do conditional forecastâ€”seen poses are conditioned on current action, produced poses are conditioned on next action.\n",
    "   3. Run the resultant poses through the action detector.\n",
    "   4. Check how accurately you can emulate the desired actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    print('Loading action model')\n",
    "    action_model = load_model(ACTION_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    train_aclass_ds = dataset['train_aclass_ds']\n",
    "    val_aclass_ds = dataset['val_aclass_ds']\n",
    "    aclass_target_names = act_names\n",
    "    if DS == 'ikeadb':\n",
    "        merge_map = {\n",
    "            'attach leg 1': '*tach',\n",
    "            'attach leg 2': '*tach',\n",
    "            'attach leg 3': '*tach',\n",
    "            'attach leg 4': '*tach',\n",
    "            'detach leg 1': '*tach',\n",
    "            'detach leg 2': '*tach',\n",
    "            'detach leg 3': '*tach',\n",
    "            'detach leg 4': '*tach',\n",
    "            'spin in': 'spin',\n",
    "            'spin out': 'spin',\n",
    "            'n/a': None\n",
    "        }\n",
    "    elif DS == 'mpii-ca2':\n",
    "        merge_map = {'n/a': None}\n",
    "    elif DS == 'h36m-2d':\n",
    "        merge_map = {}\n",
    "    else:\n",
    "        raise ValueError('unhandled datset %s' % DS)\n",
    "    # note that we're using unbalanced datasets\n",
    "    _, train_aclass_ds \\\n",
    "        = merge_actions(train_aclass_ds, merge_map, act_names)\n",
    "    aclass_target_names, val_aclass_ds \\\n",
    "        = merge_actions(val_aclass_ds, merge_map, act_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if DO_FORECAST_EVAL:\n",
    "    if DS == 'ikeadb':\n",
    "        # All actions: n/a, attach leg 1, attach leg 2, attach leg 3, attach leg 4,\n",
    "        # detach leg 1, detach leg 2, detach leg 3, detach leg 4, flip over,\n",
    "        # spin in, spin out, pick leg\n",
    "\n",
    "        # Things I haven't modelled:\n",
    "        #  1) 'detach leg N' ending the sequence\n",
    "        #  2) the \"null actions\" which act as padding\n",
    "\n",
    "        d = {\n",
    "            'flip over': ['spin out'],\n",
    "            'spin in': ['pick leg', 'flip over']\n",
    "        }\n",
    "\n",
    "        for l in range(1, 4+1):\n",
    "            attach_a = 'attach leg %d' % l\n",
    "            detach_a = 'detach leg %d' % l\n",
    "            d[attach_a] = ['spin in']\n",
    "            d.setdefault('pick leg', []).append(attach_a)\n",
    "\n",
    "            d[detach_a] = ['spin out']\n",
    "            d.setdefault('spin out', []).append(detach_a)\n",
    "    elif DS == 'mpii-ca2':\n",
    "        # All actions: n/a, screw openV, pourV, screw closeV, washV, shakeV,\n",
    "        # knife actionV, addV, spiceV, throw in garbageV, put lidV, take lidV,\n",
    "        # rip openV, fillV, stirV, spreadV, whipV, open eggV, stampV.\n",
    "        d = {\n",
    "            'stampV': ['pourV', 'shakeV'],\n",
    "            'rip openV': ['whipV', 'addV', 'screw closeV'],\n",
    "            'spiceV': ['whipV', 'stirV', 'shakeV', 'screw closeV', 'screw openV',\n",
    "                       'put lidV', 'take lidV'],\n",
    "            'whipV': ['spiceV', 'washV', 'throw in garbageV', 'stirV',\n",
    "                      'knife actionV', 'shakeV', 'pourV', 'screw openV', 'spreadV',\n",
    "                      'put lidV', 'addV'],\n",
    "            'throw in garbageV': ['addV', 'fillV', 'washV', 'open eggV', 'stirV',\n",
    "                                  'knife actionV', 'pourV', 'shakeV', 'screw openV',\n",
    "                                  'put lidV', 'take lidV'],\n",
    "            'screw openV': ['addV', 'stampV', 'rip openV', 'spiceV', 'washV',\n",
    "                            'throw in garbageV', 'stirV', 'pourV', 'screw closeV',\n",
    "                            'take lidV'],\n",
    "            'stirV': ['addV', 'spiceV', 'fillV', 'washV', 'open eggV',\n",
    "                      'throw in garbageV', 'knife actionV', 'pourV', 'shakeV',\n",
    "                      'screw openV', 'spreadV', 'screw closeV', 'put lidV',\n",
    "                      'take lidV'],\n",
    "            'pourV': ['addV', 'stampV', 'fillV', 'washV', 'whipV',\n",
    "                      'throw in garbageV', 'knife actionV', 'stirV', 'shakeV',\n",
    "                      'screw closeV', 'spreadV', 'screw openV', 'put lidV',\n",
    "                      'take lidV'],\n",
    "            'screw closeV': ['addV', 'rip openV', 'whipV', 'throw in garbageV',\n",
    "                             'stirV', 'knife actionV', 'shakeV', 'pourV',\n",
    "                             'screw openV', 'spreadV', 'put lidV', 'take lidV'],\n",
    "            'put lidV': ['addV', 'washV', 'throw in garbageV', 'stirV',\n",
    "                         'knife actionV', 'shakeV', 'pourV', 'screw closeV',\n",
    "                         'spreadV', 'screw openV', 'take lidV'],\n",
    "            'take lidV': ['rip openV', 'spiceV', 'fillV', 'washV', 'whipV',\n",
    "                          'open eggV', 'throw in garbageV', 'knife actionV', 'stirV',\n",
    "                          'pourV', 'shakeV', 'screw openV', 'spreadV', 'put lidV',\n",
    "                          'addV'],\n",
    "            'fillV': ['washV', 'throw in garbageV', 'knife actionV', 'shakeV',\n",
    "                      'pourV', 'put lidV', 'addV'],\n",
    "            'washV': ['addV', 'fillV', 'whipV', 'open eggV', 'throw in garbageV',\n",
    "                      'knife actionV', 'stirV', 'pourV', 'shakeV', 'screw openV',\n",
    "                      'put lidV', 'take lidV'],\n",
    "            'open eggV': ['washV', 'shakeV', 'throw in garbageV', 'stirV', 'addV'],\n",
    "            'addV': ['stampV', 'fillV', 'washV', 'whipV', 'throw in garbageV',\n",
    "                     'knife actionV', 'stirV', 'pourV', 'shakeV', 'screw openV',\n",
    "                     'spreadV', 'screw closeV', 'put lidV', 'take lidV'],\n",
    "            'knife actionV': ['addV', 'rip openV', 'washV', 'throw in garbageV',\n",
    "                              'stirV', 'knife actionV', 'shakeV', 'screw openV',\n",
    "                              'spreadV', 'screw closeV', 'put lidV', 'take lidV'],\n",
    "            'shakeV': ['addV', 'stampV', 'fillV', 'spiceV', 'washV', 'whipV',\n",
    "                       'open eggV', 'throw in garbageV', 'knife actionV', 'stirV',\n",
    "                       'pourV', 'screw closeV', 'screw openV', 'put lidV',\n",
    "                       'take lidV'],\n",
    "            'spreadV': ['washV', 'whipV', 'throw in garbageV', 'knife actionV',\n",
    "                        'stirV', 'pourV', 'shakeV', 'screw openV', 'screw closeV',\n",
    "                        'addV']\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError('unsupported ds ' + DS)\n",
    "\n",
    "    transition_dict = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if use_cond and DO_FORECAST_EVAL:\n",
    "    blocks_X = []\n",
    "    blocks_Y = []\n",
    "    print('Working on blocks')\n",
    "    ctr = 0\n",
    "    for item in val_aclass_ds:\n",
    "        ctr += 1\n",
    "        if ctr == 1 or 0 == (ctr % 500):\n",
    "            print('Working on classifier dataset item %d/%d' % (ctr, len(val_aclass_ds)))\n",
    "\n",
    "        poses = item['poses']\n",
    "        action_id_simple = item['action_label']\n",
    "        action_id_orig = item['action_label_orig']\n",
    "        actions = item['actions']\n",
    "\n",
    "        action_name_orig = act_names[action_id_orig]\n",
    "        # some poses, some zeros\n",
    "        # we'll cross over half way through\n",
    "        pose_block = np.concatenate([poses, np.zeros_like(poses)], axis=0)\n",
    "        \n",
    "        succs = transition_dict[action_name_orig]\n",
    "        np.random.shuffle(succs)\n",
    "\n",
    "        for next_action_name_orig in succs[:3]:\n",
    "            # do a forecast for each possible subsequent action\n",
    "            next_action_id_orig = act_names.index(next_action_name_orig)\n",
    "            next_action_name_simple = merge_map.get(next_action_name_orig, next_action_name_orig)\n",
    "            if next_action_name_simple is None:\n",
    "                continue\n",
    "            next_action_id_simple = aclass_target_names.index(next_action_name_simple)\n",
    "    \n",
    "            action_block = np.concatenate([\n",
    "                actions,\n",
    "                np.full((len(poses), ), next_action_id_orig)\n",
    "            ])\n",
    "            # v XXX: remove this\n",
    "            # Comment out to feed in garbage labels (n/a action) to see\n",
    "            # whether it makes a difference.\n",
    "            # action_block = np.concatenate([\n",
    "            #     actions,\n",
    "            #     np.full((len(poses), ), 0)\n",
    "            # ])\n",
    "            # ^ XXX: remove this\n",
    "            assert len(action_block) == len(pose_block)\n",
    "    \n",
    "            p_completion, split_time = make_completion(pose_block, action_block, False)\n",
    "            assert split_time == len(poses), (split_time, len(poses))\n",
    "            \n",
    "            # We mostly give (known) pose context, but then switch over to\n",
    "            # the new frames for this long. Will have to tune exact amount.\n",
    "            num_forecast_frames = min(2 * db.aclass_act_length, len(poses))\n",
    "            p_completion = p_completion[:split_time+num_forecast_frames][-db.aclass_full_length:]\n",
    "            assert len(p_completion) == db.aclass_full_length\n",
    "\n",
    "            blocks_X.append(p_completion)\n",
    "            blocks_Y.append(next_action_id_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if use_cond:\n",
    "    # as above, but making \"true dataset\"\n",
    "    blocks_true_X = []\n",
    "    blocks_true_Y = []\n",
    "    for item in val_aclass_ds:\n",
    "        poses = item['poses']\n",
    "        action_id = item['action_label']\n",
    "\n",
    "        blocks_true_X.append(poses[-db.aclass_full_length:])\n",
    "        blocks_true_Y.append(action_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_cond and DO_FORECAST_EVAL: \n",
    "    print('Got %d classification blocks' % len(blocks_X))\n",
    "    X = np.stack(blocks_X, axis=0)\n",
    "    Y = np.array(blocks_Y)\n",
    "    assert Y.ndim == 1, Y.shape\n",
    "    assert len(X) == len(Y), (X.shape, Y.shape)\n",
    "    assert X.ndim == 3, X.shape\n",
    "    \n",
    "    X_clean = classifier_transform(X)\n",
    "    \n",
    "    Y_pred = action_model.predict(X_clean, batch_size=1000).argmax(axis=-1)\n",
    "    \n",
    "    print('Results for generated poses:')\n",
    "    print(classification_report(Y, Y_pred, target_names=aclass_target_names))\n",
    "    cm = confusion_matrix(Y, Y_pred)\n",
    "    plot_confusion_matrix(cm, aclass_target_names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if use_cond: \n",
    "    print('Results for actual input data:')\n",
    "    true_X = np.stack(blocks_true_X, axis=0)\n",
    "    true_Y = np.array(blocks_true_Y)\n",
    "    true_X_clean = classifier_transform(true_X)\n",
    "    true_Y_pred = action_model.predict(true_X_clean).argmax(axis=-1)\n",
    "    print(classification_report(true_Y, true_Y_pred, target_names=aclass_target_names))\n",
    "    true_cm = confusion_matrix(true_Y, true_Y_pred)\n",
    "    plot_confusion_matrix(true_cm, aclass_target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Improvement ideas:\n",
    "\n",
    "- Use shorter sequences.\n",
    "\n",
    "   **Result:** I think I was already using 32-frame sequences, because Keras complains when I don't give it length-32 sequences (and that's not very long to begin with). Will have to figure out why it's not accepting longer sequences. That said, probably more interesting to try other stuff now that I know current pose seqs are short enough.\n",
    "- Ignore flip over (too much occlusion) and merge spin in/spin out (spin) and attach/detach (*tach).\n",
    "\n",
    "   **Result:** currently merging the spin and Xtach actions, but not removing \"flip over\". Works okay, but bias towards spin actions is very obvious; once you put the spin actions through a transition, you get a bias towards Xtach actions, which are the only ones classified well! At least that shows the model is able to learn what transitions between different things look like (and perhaps that the DMM is doing transitions correctly? IDK).\n",
    "- Try higher-dimensional latent representation for DMM.\n",
    "\n",
    "   **Result:** still need to do this.\n",
    "- Train and test action recogniser on much longer sequences. Without context (e.g. showing the person spinning something in and then picking up the leg), it can be hard to detect an action (i.e. screwing in another leg). During test, it probably makes sense to feed the action classifier _all_ of the observed poses, followed by the forecasted suffix.\n",
    "\n",
    "   **Result:** Works really well for action classification from CPM-generated reference poses (10pp boost from low 60s to ~70%). Remains to be seen how well it works for other things.\n",
    "- On IkeaDB, consider testing only on the sequences where assembly is being taken out on a table. Can discard ones on the floor if they're unlearnable.\n",
    "\n",
    "   **Result:** not sure yet. Will need to add flags for \"is this happening on the floor?\" to figure out which to drop.\n",
    "\n",
    "Other things:\n",
    "\n",
    "- Might want to consider JHMDB. It's about 40 frames per sequence. **Edit:** had a look and some of them are even shorter. Will be hard to learn anything useful this way.\n",
    "- Fix training classifier on generated poses.\n",
    "- Try to get a sequence of some fixed pose type, then forecast into the future under the assumption that the action continues. Verify that the forecasted poses, when fed into the action classifier on their own, correspond to the right action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reconstructing rather than forecasting\n",
    "\n",
    "The next few cells will be similar to the ones above. However, instead of trying to add a novel completion to a some action classification data, the cells will attempt to reconstruct the tail of a normal action classification dataset (ofc. generator is conditioned on true actions to do that )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def forecast_on_batch(poses, forecast_length, actions=None):\n",
    "    \"\"\"Extends a batch of pose sequences by the desired forecast length.\"\"\"\n",
    "    assert poses.ndim == 3, \"Poses should be batch*time*dim\"\n",
    "    assert actions is None or actions.ndim == 3, \\\n",
    "        \"Actions should be batch*time*nacts\"\n",
    "    prefix_length = poses.shape[1]\n",
    "    poses = poses.astype('float32')\n",
    "    batch_size = len(poses)\n",
    "    if actions is not None:\n",
    "        assert actions.ndim == 3\n",
    "        assert actions.shape[0] == batch_size\n",
    "        assert actions.shape[1] == prefix_length + forecast_length\n",
    "        actions = actions.astype(config.floatX)\n",
    "        prefix_actions = actions[:, :prefix_length]\n",
    "    else:\n",
    "        prefix_actions = None\n",
    "        \n",
    "    forecast = np.zeros((batch_size, forecast_length, poses.shape[-1]),\n",
    "                        dtype=config.floatX)\n",
    "    mask = np.ones_like(poses, dtype=config.floatX)\n",
    "    # ignore mu_z/logcov_z for now. will have to test later whether\n",
    "    # using mu_z in place of z improves performance\n",
    "    z, mu_z, logcov_z = DKF_evaluate.infer(dkf, poses,\n",
    "                                           mask, cond_vals=prefix_actions)\n",
    "    # take just last timestep\n",
    "    z = z[:, -1:]\n",
    "    # z needs to be 3D (nsamples, time, stochdim)\n",
    "    assert z.ndim == 3 and z.shape[:2] == (batch_size, 1)\n",
    "    \n",
    "    for t in range(prefix_length, prefix_length + forecast_length):\n",
    "        # completion based on transition prior only\n",
    "        if use_cond:\n",
    "            mu, logcov = dkf.transition_fxn(z, actions[:, t:t+1])\n",
    "        else:\n",
    "            mu, logcov = dkf.transition_fxn(z)\n",
    "        z = DKF_evaluate.sampleGaussian(mu, logcov).astype(config.floatX)\n",
    "        e = dkf.emission_fxn(z)\n",
    "        assert e.ndim == 3 and e.shape[:2] == (batch_size, 1)\n",
    "        forecast[:, t - prefix_length] = e[:, 0]\n",
    "\n",
    "    return forecast\n",
    "\n",
    "def forecast_batches(poses, forecast_length, actions=None, batch_size=256):\n",
    "    \"\"\"Splits input into batches and forecasts on each.\"\"\"\n",
    "    assert poses.ndim == 3, poses.shape\n",
    "    if actions is not None:\n",
    "        pass_actions = True\n",
    "        # must be one-hot\n",
    "        assert actions.ndim == 3, actions.shape\n",
    "        assert actions.shape[0] == poses.shape[0], \\\n",
    "            (actions.shape, poses.shape)\n",
    "        assert actions.shape[1] == forecast_length + poses.shape[1], \\\n",
    "            (actions.shape, poses.shape)\n",
    "    else:\n",
    "        pass_actions = False\n",
    "\n",
    "    num_batches = int(np.ceil(len(poses) / float(batch_size)))\n",
    "    forecast_list = []\n",
    "    print('Forecasting in %d batches' % num_batches)\n",
    "    for bnum in tqdm.tqdm(range(num_batches)):\n",
    "        start = bnum * batch_size\n",
    "        stop = start + batch_size\n",
    "        batch_poses = poses[start:stop]\n",
    "        if pass_actions:\n",
    "            batch_actions = actions[start:stop]\n",
    "        else:\n",
    "            batch_actions = None\n",
    "        forecast = forecast_on_batch(batch_poses, forecast_length, batch_actions)\n",
    "        forecast_list.append(forecast)\n",
    "\n",
    "    joined_forecasts = np.concatenate(forecast_list, axis=0)\n",
    "    \n",
    "    return joined_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def do_forecast_completion_eval(to_predict=db.aclass_act_length, real_labels=True, vis=True):\n",
    "    # we're only predicting a small fraction of the time steps (like 8/128 here, IIRC)\n",
    "    # can turn the fraction up; main aim is to be better than baseline using null\n",
    "    # action, or baseline using mirroring or s.th\n",
    "    poses_batched = np.zeros((len(val_aclass_ds),\n",
    "                              db.aclass_full_length - to_predict,\n",
    "                              dkf.params['dim_observations']),\n",
    "                            dtype=config.floatX)\n",
    "    actions_batched = np.zeros((len(val_aclass_ds),\n",
    "                                db.aclass_full_length,\n",
    "                                db.num_actions),\n",
    "                              dtype=config.floatX)\n",
    "    simplified_actions = np.zeros((len(val_aclass_ds),),\n",
    "                                  dtype=int)\n",
    "    print('Constructing batched data')\n",
    "    for idx, item in enumerate(val_aclass_ds):\n",
    "        poses = item['poses']\n",
    "        action_id_simple = item['action_label']\n",
    "        action_id_orig = item['action_label_orig']\n",
    "        actions = item['actions']\n",
    "        if real_labels:\n",
    "            one_hot_actions = one_hot_cat(actions, db.num_actions)\n",
    "        else:\n",
    "            one_hot_actions = np.zeros(actions.shape + (db.num_actions,),\n",
    "                                       dtype=config.floatX)\n",
    "            # use null label all across sequence\n",
    "            one_hot_actions[:, 0] = 1\n",
    "        \n",
    "        actions_batched[idx] = one_hot_actions\n",
    "        poses_batched[idx] = poses[:-to_predict]\n",
    "        simplified_actions[idx] = action_id_simple\n",
    "    \n",
    "    print('Forecasting on batches')\n",
    "    if not use_cond:\n",
    "        print('throwing out actions')\n",
    "        actions_batched = None\n",
    "    forecasts = forecast_batches(poses_batched,\n",
    "                                 to_predict,\n",
    "                                 actions=actions_batched,\n",
    "                                 batch_size=256)\n",
    "    \n",
    "    if vis:\n",
    "        X = np.concatenate([poses_batched, forecasts], axis=1)\n",
    "        # next one should be *simplified* actions!\n",
    "        Y = simplified_actions\n",
    "        assert Y.ndim == 1, Y.shape\n",
    "        assert len(X) == len(Y), (X.shape, Y.shape)\n",
    "        assert X.ndim == 3, X.shape\n",
    "        X_clean = classifier_transform(X)\n",
    "        Y_pred_prob = action_model.predict(X_clean, batch_size=1000)\n",
    "        Y_pred = Y_pred_prob.argmax(axis=-1)\n",
    "        mnll = np.mean(-np.log(Y_pred_prob[np.arange(len(Y)), Y]))\n",
    "        print('Mean negative log likelihood (MNLL): %.5f' % mnll)\n",
    "        acc = np.mean(Y_pred == Y)\n",
    "        print('Accuracy: %.5f' % acc)\n",
    "        print(classification_report(Y, Y_pred, target_names=aclass_target_names))\n",
    "        cm = confusion_matrix(Y, Y_pred)\n",
    "        plot_confusion_matrix(cm, aclass_target_names)\n",
    "        plt.show()\n",
    "    \n",
    "    return poses_batched, forecasts, actions_batched, simplified_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DO_EASY_FORECAST_EVAL:\n",
    "    for to_predict in [2 * db.aclass_act_length, db.aclass_full_length - 1]:\n",
    "        print('to_predict = %d' % to_predict)\n",
    "        print('Real labels:')\n",
    "        poses_batched, forecasts, actions_batched, simplified_actions \\\n",
    "            = do_forecast_completion_eval(to_predict=to_predict,\n",
    "                                          real_labels=True)\n",
    "        print('\\nNull action labels:')\n",
    "        poses_batched, forecasts, actions_batched, simplified_actions \\\n",
    "            = do_forecast_completion_eval(to_predict=to_predict,\n",
    "                                          real_labels=False)\n",
    "        print('\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation strategy 2: generated poses\n",
    "\n",
    "Get a random latent variable (drawn from standard Gaussian), then evolve it using action-conditional transition model. See whether the action classifier can recover the original action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_cond: \n",
    "    # don't make it too large because LSTM is unstable\n",
    "    from common_pp.act_class_model import make_model\n",
    "    sample_class_length = 48\n",
    "    sample_class_actions = action_model.output_shape[1]\n",
    "    sample_class_indim = action_model.input_shape[-1]\n",
    "    sample_class_action_model = make_model(sample_class_length,\n",
    "                                           sample_class_indim,\n",
    "                                           sample_class_actions)\n",
    "    sample_class_action_model.set_weights(action_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sample_XY(samples_per_act):\n",
    "    # add 1 step to input because classifier transform will remove\n",
    "    # a time step when it cats in pose deltas from previous frame\n",
    "    steps_per_act = sample_class_length + 1\n",
    "    sample_X_blocks = []\n",
    "    sample_Y_blocks = []\n",
    "    for act_name in act_names:\n",
    "        act_name_simple = merge_map.get(act_name, act_name)\n",
    "        if act_name_simple is None:\n",
    "            # skip it\n",
    "            continue\n",
    "        simple_sources = len(\n",
    "            {k for k, v in merge_map.items() if v == act_name_simple}\n",
    "            .union ({act_name_simple} if act_name_simple in act_names else set()))\n",
    "        batch_size = int(np.ceil(samples_per_act / float(simple_sources)))\n",
    "        act_idx = act_names.index(act_name)\n",
    "        act_idx_simple = aclass_target_names.index(act_name_simple)\n",
    "        one_hot_act_shape = (steps_per_act, len(act_names))\n",
    "        one_hot_acts = np.zeros(one_hot_act_shape, dtype=theano.config.floatX)\n",
    "        one_hot_acts[..., act_idx] = 1\n",
    "        assert not np.any(np.isnan(batch_size))\n",
    "        assert not np.any(np.isnan(steps_per_act))\n",
    "        assert not np.any(np.isnan(one_hot_acts))\n",
    "        sample_X, sample_Z = dkf.sample(nsamples=batch_size,\n",
    "                                        T=steps_per_act,\n",
    "                                        U=one_hot_acts)\n",
    "        assert not np.any(np.isnan(sample_Z))\n",
    "        assert not np.any(np.isnan(sample_X))\n",
    "        sample_X_blocks.append(sample_X)\n",
    "        sample_Y_blocks.append([act_idx_simple] * batch_size)\n",
    "    X = np.concatenate(sample_X_blocks, axis=0)\n",
    "    Y = np.concatenate(sample_Y_blocks, axis=0)\n",
    "    assert Y.ndim == 1, Y.shape\n",
    "    assert len(X) == len(Y), (X.shape, Y.shape)\n",
    "    assert X.ndim == 3, X.shape\n",
    "    \n",
    "    assert not np.any(np.isnan(X))\n",
    "    \n",
    "    X_clean = classifier_transform(X)\n",
    "    \n",
    "    assert not np.any(np.isnan(X))\n",
    "    \n",
    "    return X_clean, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if use_cond:\n",
    "    samples_per_act = 2048\n",
    "    X_clean, Y = sample_XY(samples_per_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if use_cond: \n",
    "    Y_pred_prob = sample_class_action_model.predict(X_clean, batch_size=10000)\n",
    "    Y_pred_prob[Y_pred_prob < 1e-5] = 1e-5\n",
    "    Y_pred_prob /= np.sum(Y_pred_prob)\n",
    "    mnll = np.mean(-np.log(Y_pred_prob[np.arange(len(Y)), Y]))\n",
    "    print('Mean negative log likelihood: %.5f' % mnll)\n",
    "    Y_pred = Y_pred_prob.argmax(axis=-1)\n",
    "    acc = np.mean(Y_pred == Y)\n",
    "    print('accuracy: %.5f' % acc)\n",
    "    \n",
    "    print('Results for sampled, action-conditioned poses:')\n",
    "    print(classification_report(Y, Y_pred, target_names=aclass_target_names))\n",
    "    cm = confusion_matrix(Y, Y_pred)\n",
    "    plot_confusion_matrix(cm, aclass_target_names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can try to train an action classifier on the generated poses. This will tell us whether they reflect _anything at all_, even if they don't reflect real poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from common_pp.act_class_model import make_model\n",
    "\n",
    "    train_X, train_Y = sample_XY(8192)\n",
    "    train_Y = one_hot_cat(train_Y, len(aclass_target_names))\n",
    "    val_X, val_Y = sample_XY(1024)\n",
    "    val_Y = one_hot_cat(val_Y, len(aclass_target_names))\n",
    "    assert not np.any(np.isnan(train_X))\n",
    "    assert not np.any(np.isnan(train_Y))\n",
    "    assert not np.any(np.isnan(val_X))\n",
    "    assert not np.any(np.isnan(val_Y))\n",
    "\n",
    "    model = make_model(train_X.shape[1],\n",
    "                           train_X.shape[2],\n",
    "                           len(aclass_target_names))\n",
    "    model.fit(train_X,\n",
    "                  train_Y,\n",
    "                  batch_size=64,\n",
    "                  nb_epoch=10,\n",
    "                  validation_data=(val_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    Y_pred = model.predict(val_X, batch_size=10000).argmax(axis=-1)    \n",
    "    print('Results for sampled, action-conditioned poses:')\n",
    "    print(classification_report(val_Y, Y_pred, target_names=aclass_target_names))\n",
    "    cm = confusion_matrix(val_Y, Y_pred)\n",
    "    plot_confusion_matrix(cm, aclass_target_names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I'm going to compare that to the ground truth validation set. For this to be a fair comparison, I will have to balance the ground truth dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if use_cond:\n",
    "    # train_aclass_ds_bal = balance_aclass_ds(train_aclass_ds, aclass_target_names)\n",
    "    val_aclass_ds_bal = balance_aclass_ds(val_aclass_ds, aclass_target_names)\n",
    "    \n",
    "    blocks_true_X = []\n",
    "    blocks_true_Y = []\n",
    "    for item in val_aclass_ds_bal:\n",
    "        poses = item['poses']\n",
    "        action_id = item['action_label']\n",
    "        \n",
    "        # assertion is here because I was previously shortening the sequence\n",
    "        # to only include the last db.aclass_full_length poses, but I'm not\n",
    "        # sure whether that was even needed.\n",
    "        assert len(poses) == db.aclass_full_length\n",
    "\n",
    "        blocks_true_X.append(poses)\n",
    "        blocks_true_Y.append(action_id)\n",
    "\n",
    "    print('Results for actual input data:')\n",
    "    true_X = np.stack(blocks_true_X, axis=0)\n",
    "    true_Y = np.array(blocks_true_Y)\n",
    "    true_X_clean = classifier_transform(true_X)\n",
    "    true_Y_pred_prob = action_model.predict(true_X_clean)\n",
    "    mnll = np.mean(-np.log(true_Y_pred_prob[np.arange(len(true_Y)), true_Y]))\n",
    "    print('mnll: %.5f' % mnll)\n",
    "    true_Y_pred = true_Y_pred_prob.argmax(axis=-1)\n",
    "    acc = np.mean(true_Y_pred == true_Y)\n",
    "    print('accuracy: %.5f' % acc)\n",
    "    print(classification_report(true_Y, true_Y_pred, target_names=aclass_target_names))\n",
    "    true_cm = confusion_matrix(true_Y, true_Y_pred)\n",
    "    plot_confusion_matrix(true_cm, aclass_target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
